<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <!-- <header name = "Access-Control-Allow-Origin" value = "*" > -->

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible"  content="ie=edge">
  <title>HTML5音频可视化频谱跳动代码</title>
  <style>
    * {
      margin: 0;
      padding: 0;
    }

    #canvas {
      display: block;
      background: #000;
    }
  </style>
</head>

<body>
  <audio  id="myaudio" controls crossOrigin="anonymous"  src="./mp3.mp3"></audio>
  <input type="range" id="myRange" max="380"> 
  <canvas id="canvas"></canvas>
  <script>
    window.onload = function () {
      var count = 120;
      range = document.querySelector('#myRange')
      range.addEventListener('change', function(e){
          console.log(e);
          count = e.target.valueAsNumber
      })
      
      // 创建音频上下文对象
      var oCtx = new AudioContext();
      oCtx.resume().then(function(){
        var oAudio = document.getElementById('myaudio');
        canvas.onclick = function () {
            if (oAudio.paused) {
            oAudio.play();
            if(!draw.draw)
            {
                draw();
                draw.draw = true
            }else{
                return;
            }
            } else {
            oAudio.pause();
            
            
            window.cancelAnimationFrame(draw);
            }
        }
        // console.log(oCtx);
        // 创建媒体源,除了audio本身可以获取，也可以通过oCtx对象提供的api进行媒体源操作
        var audioSrc = oCtx.createMediaElementSource(oAudio);
        // 创建分析机 
        var analyser = oCtx.createAnalyser();
        // 媒体源与分析机连接
        audioSrc.connect(analyser);
        // 输出的目标：将分析机分析出来的处理结果与目标点（耳机/扬声器）连接
        analyser.connect(oCtx.destination);

        // 效果（实现的具体方法）
        // 绘制音频图的条数(fftSize)
        /*
            根据分析音频的数据去获取音频频次界定音频图的高度
            放在与音频频次等长的8位无符号字节数组
            Uint8Array:初始化默认值为1024
        */
        // 利用cancas渐变进行音频绘制
        var ctx = canvas.getContext('2d');
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
        var oW = canvas.width;
        var oH = canvas.height;
        var color1 = ctx.createLinearGradient(oW / 2, oH / 2 - 30, oW / 2, oH / 2 - 100);
        var color2 = ctx.createLinearGradient(oW / 2, oH / 2 + 30, oW / 2, oH / 2 + 100);
        color1.addColorStop(0, '#000');
        color1.addColorStop(.5, '#069');
        color1.addColorStop(1, '#f6f');
        color2.addColorStop(0, '#000');
        color2.addColorStop(.5, '#069');
        color2.addColorStop(1, '#f6f');
        // 音频图的条数
        
        // 缓冲区:进行数据的缓冲处理，转换成二进制数据
        var voiceHeight = new Uint8Array(analyser.frequencyBinCount);
        var meterWidth = 10
        console.log(voiceHeight);
        var capYPositionArray = []
        var rLength = 150
        var hue = 0
        var offset = 0
        function draw() {
            // 将当前的频率数据复制到传入的无符号字节数组中，做到实时连接
            analyser.getByteFrequencyData(voiceHeight);
            // console.log(voiceHeight);
            
            // 自定义获取数组里边数据的频步
            var step = Math.round(voiceHeight.length / count/5);
            var color3 = ctx.createLinearGradient(oW / 2, oH / 2 - 30, oW / 2, oH / 2 - 150);
            color3.addColorStop(0,  "rgb(21, 228, 48)");
            color3.addColorStop(1,  "rgb(228, 58, 21)");
            
            ctx.lineWidth = 3;
            
            

            
            ctx.clearRect(0, 0, oW, oH);
            offset+=voiceHeight[0]/100;
            for (var i = 0; i < count; i++) {
                ctx.beginPath();
                var hue = (360/count*i+offset)%360
                ctx.strokeStyle = `hsl(${ hue }, 90%, 50%)`;
                ctx.fillStyle = `hsl(${ hue }, 90%, 50%)`;
                var angle = 360/count * i;
                var audioHeight = voiceHeight[step * i];
                var nextAngle = 360/count * (i+1)
                var next = (i!=count-1)?voiceHeight[step*(i+1)]:voiceHeight[0]

                var x = oW/2 + Math.cos(angle*(Math.PI / 180))*rLength
                var y = oH/2 + Math.sin(angle*(Math.PI / 180))*rLength
                var eX = oW/2 + Math.cos(angle*(Math.PI / 180))*(rLength+(audioHeight)/2.5)
                var eY = oH/2 + Math.sin(angle*(Math.PI / 180))*(rLength+(audioHeight)/2.5)
                var dotX = oW/2 + Math.cos(angle*(Math.PI / 180))*(rLength+(audioHeight)/(2))
                var dotY = oH/2 + Math.sin(angle*(Math.PI / 180))*(rLength+(audioHeight)/(2))
                var nX = oW/2 + Math.cos(nextAngle*(Math.PI / 180))*(rLength+(next)/2.5)
                var nY = oH/2 + Math.sin(nextAngle*(Math.PI / 180))*(rLength+(next)/2.5)

                ctx.lineWidth = 8;
                drawDot(dotX, dotY)
                drawOutline(x,y, eX, eY)
                ctx.lineWidth = 1;
                drawOutCur(eX, eY,nX , nY)
                // ctx.moveTo(dx,dy);
                // ctx.lineTo(edX,edY)
                ctx.stroke();

                // ctx.fillRect(20,20,150,100);
                ctx.fill();
            }
            // if(!oAudio.paused){
            window.requestAnimationFrame(draw);
            // }
        }
        function drawDot(dotX, dotY) {
            // ctx.moveTo(dotX,dotY);
            // ctx.lineTo(dotX+1,dotY+1);
            ctx.fillRect(dotX-2,dotY-2,3,3);
            
        }

        function drawOutline(x,y, eX, eY){

            ctx.moveTo(x,y);
            ctx.lineTo(eX,eY);
        }

        function drawOutCur(eX, eY,nX , nY){
            ctx.moveTo(eX, eY);
            ctx.lineTo(nX, nY);
        }
      })

      


      /*
        analyserNode 提供了时时频率以及时间域的分析信息
            允许你获取实时的数据，并进行音频可视化
            analyserNode接口的fftSize属性
                fftSize:无符号长整型值，用于确定频域的FFT(快速傅里叶变换)
                ffiSize属性值是从32位到32768范围内的2的非零幂,默认值是2048
      */
    }
  </script>
</body>

</html>